{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMlTOcQYOUdItAQLOKdv8kX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alfredqbit/datasciencecoursera/blob/master/sepulvedaADDS-8515-5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Canonical Correlation Analysis and Multivariate Regression on the Linnerud Dataset\n",
        "\n",
        "This notebook implements Canonical Correlation Analysis (CCA) and Multivariate Multiple Regression (MVR)\n",
        "on the Linnerud exercise dataset, following the methodology described in the report."
      ],
      "metadata": {
        "id": "KDc_-7S7MeuS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.datasets import load_linnerud\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cross_decomposition import CCA\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "%pip install statsmodels --quiet\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.multivariate.manova import MANOVA\n",
        "\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "FIG_DIR = \"figures\"\n",
        "os.makedirs(FIG_DIR, exist_ok=True)"
      ],
      "metadata": {
        "id": "KP8TxdDTMhO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helper functions: correlation matrix, VIFs, and canonical loadings and redundancy"
      ],
      "metadata": {
        "id": "_Lr1qrFZND5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def col_corr_matrix(A, B):\n",
        "    \"\"\"Correlation matrix between columns of A and B.\"\"\"\n",
        "    A0 = A - A.mean(axis=0)\n",
        "    B0 = B - B.mean(axis=0)\n",
        "    cov = A0.T @ B0 / (A.shape[0] - 1)\n",
        "    sdA = A0.std(axis=0, ddof=1)\n",
        "    sdB = B0.std(axis=0, ddof=1)\n",
        "    return cov / np.outer(sdA, sdB)\n",
        "\n",
        "def redundancy_indices(loadings, rho_sq):\n",
        "    \"\"\"\n",
        "    Redundancy indices for one set given loadings and squared canonical corrs.\n",
        "    loadings: (variables x components) correlations with canonical variates\n",
        "    rho_sq : array of squared canonical correlations\n",
        "    \"\"\"\n",
        "    var_explained = (loadings ** 2).mean(axis=0)\n",
        "    return var_explained * rho_sq\n",
        "\n",
        "def compute_vif(X_df):\n",
        "    vifs = {}\n",
        "    for col in X_df.columns:\n",
        "        X_other = X_df.drop(columns=[col])\n",
        "        y = X_df[col]\n",
        "        model = LinearRegression().fit(X_other, y)\n",
        "        r2 = model.score(X_other, y)\n",
        "        vif = 1.0 / (1.0 - r2)\n",
        "        vifs[col] = vif\n",
        "    return pd.Series(vifs, name=\"VIF\")"
      ],
      "metadata": {
        "id": "H4kku5ZbNH1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load dataset and basic EDA (Step 1)"
      ],
      "metadata": {
        "id": "iex5r6sIMtUb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "linnerud = load_linnerud()\n",
        "\n",
        "X_ex = pd.DataFrame(linnerud.data, columns=linnerud.feature_names)        # Chins, Situps, Jumps\n",
        "Y_phys = pd.DataFrame(linnerud.target, columns=linnerud.target_names)     # Weight, Waist, Pulse\n",
        "\n",
        "print(\"Exercise variables (X):\")\n",
        "display(X_ex.head())\n",
        "\n",
        "print(\"\\nPhysiological variables (Y):\")\n",
        "display(Y_phys.head())\n",
        "\n",
        "print(\"\\nX info:\")\n",
        "print(X_ex.info())\n",
        "\n",
        "print(\"\\nY info:\")\n",
        "print(Y_phys.info())\n",
        "\n",
        "print(\"\\nSummary statistics for X:\")\n",
        "display(X_ex.describe())\n",
        "\n",
        "print(\"\\nSummary statistics for Y:\")\n",
        "display(Y_phys.describe())\n",
        "\n",
        "print(\"\\nMissing values in X:\")\n",
        "print(X_ex.isna().sum())\n",
        "print(\"\\nMissing values in Y:\")\n",
        "print(Y_phys.isna().sum())\n"
      ],
      "metadata": {
        "id": "4UYCD_rDMrz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Correlation heatmap and simple outlier check"
      ],
      "metadata": {
        "id": "hYzyeGqXMz_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine for correlation inspection\n",
        "df_all = pd.concat([X_ex, Y_phys], axis=1)\n",
        "corr = df_all.corr()\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\",\n",
        "            annot_kws={\"size\": 9}, cbar_kws={\"label\": \"Correlation\"})\n",
        "plt.title(\"Correlation Matrix: Exercise and Physiological Variables\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(FIG_DIR, \"linnerud_correlation_matrix.png\"), dpi=300)\n",
        "plt.show()\n",
        "\n",
        "z_scores = (df_all - df_all.mean()) / df_all.std(ddof=1)\n",
        "outlier_mask = (z_scores.abs() > 3)\n",
        "print(\"Potential outliers (|z| > 3) per variable:\")\n",
        "print(outlier_mask.sum())"
      ],
      "metadata": {
        "id": "Rs56BUcxM35P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Standardization (Step 2)"
      ],
      "metadata": {
        "id": "qBp_2QIsM7Vx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize each block separately\n",
        "scaler_X = StandardScaler()\n",
        "scaler_Y = StandardScaler()\n",
        "\n",
        "X_scaled = scaler_X.fit_transform(X_ex)\n",
        "Y_scaled = scaler_Y.fit_transform(Y_phys)\n",
        "\n",
        "X_scaled_df = pd.DataFrame(X_scaled, columns=X_ex.columns)\n",
        "Y_scaled_df = pd.DataFrame(Y_scaled, columns=Y_phys.columns)\n",
        "\n",
        "X_scaled_df.head(), Y_scaled_df.head()"
      ],
      "metadata": {
        "id": "fm4j2RmYNAYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Canonical Correlation Analysis (Step 2 CCA)\n",
        "\n",
        "Note: CCA naturally takes two inputs (X, Y), so forcing it into a single sklearn Pipeline is awkward. We keep it as a clean, modular block using the standardized matrices."
      ],
      "metadata": {
        "id": "dl8T_QkJNLKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CCA with up to min(p, q) = 3 components\n",
        "cca = CCA(n_components=3)\n",
        "cca.fit(X_scaled, Y_scaled)\n",
        "\n",
        "X_c, Y_c = cca.transform(X_scaled, Y_scaled)  # canonical variates\n",
        "\n",
        "canonical_corrs = np.array([\n",
        "    np.corrcoef(X_c[:, k], Y_c[:, k])[0, 1]\n",
        "    for k in range(3)\n",
        "])\n",
        "\n",
        "print(\"Canonical correlations:\")\n",
        "for k, rho in enumerate(canonical_corrs, start=1):\n",
        "    print(f\"  rho_{k} = {rho:.3f}\")\n",
        "\n",
        "# Canonical loadings: correlations of original vars with canonical variates\n",
        "load_XU = col_corr_matrix(X_scaled, X_c)\n",
        "load_YV = col_corr_matrix(Y_scaled, Y_c)\n",
        "\n",
        "load_XU_df = pd.DataFrame(load_XU, index=X_ex.columns,\n",
        "                          columns=[f\"u{k}\" for k in range(1, 4)])\n",
        "load_YV_df = pd.DataFrame(load_YV, index=Y_phys.columns,\n",
        "                          columns=[f\"v{k}\" for k in range(1, 4)])\n",
        "\n",
        "print(\"\\nCanonical loadings: Exercise variables on U\")\n",
        "display(load_XU_df)\n",
        "\n",
        "print(\"\\nCanonical loadings: Physiological variables on V\")\n",
        "display(load_YV_df)\n",
        "\n",
        "rho_sq = canonical_corrs ** 2\n",
        "red_Y_given_X = redundancy_indices(load_YV, rho_sq)\n",
        "red_X_given_Y = redundancy_indices(load_XU, rho_sq)\n",
        "\n",
        "print(\"\\nRedundancy indices (Y | X):\", np.round(red_Y_given_X, 3))\n",
        "print(\"Sum redundancy Y | X:\", red_Y_given_X.sum())\n",
        "print(\"Redundancy indices (X | Y):\", np.round(red_X_given_Y, 3))\n",
        "print(\"Sum redundancy X | Y:\", red_X_given_Y.sum())"
      ],
      "metadata": {
        "id": "xswZiQSZNPE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CCA scatterplots (canonical variates)"
      ],
      "metadata": {
        "id": "H1oy61TLNT7j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scatterplot for first canonical pair\n",
        "plt.figure(figsize=(6, 5))\n",
        "plt.scatter(X_c[:, 0], Y_c[:, 0])\n",
        "plt.axhline(0, color=\"gray\", linewidth=0.8)\n",
        "plt.axvline(0, color=\"gray\", linewidth=0.8)\n",
        "plt.xlabel(\"u1 (exercise canonical variate)\")\n",
        "plt.ylabel(\"v1 (physiological canonical variate)\")\n",
        "plt.title(\"CCA: First Canonical Variates (u1 vs v1)\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(FIG_DIR, \"cca_u1_v1_scatter.png\"), dpi=300)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "plt.scatter(X_c[:, 1], Y_c[:, 1])\n",
        "plt.axhline(0, color=\"gray\", linewidth=0.8)\n",
        "plt.axvline(0, color=\"gray\", linewidth=0.8)\n",
        "plt.xlabel(\"u2 (exercise canonical variate)\")\n",
        "plt.ylabel(\"v2 (physiological canonical variate)\")\n",
        "plt.title(\"CCA: Second Canonical Variates (u2 vs v2)\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(FIG_DIR, \"cca_u2_v2_scatter.png\"), dpi=300)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OHThIkkdNXL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "VIF for predictors"
      ],
      "metadata": {
        "id": "V_e6qsbXNu4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vif_series = compute_vif(X_ex)\n",
        "print(\"Variance Inflation Factors (VIF):\")\n",
        "display(vif_series)"
      ],
      "metadata": {
        "id": "ksDOPRagNzLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimized pipeline for Multivariate Regression: fit and metrics (Step 3 MVR)"
      ],
      "metadata": {
        "id": "o9bOUqGONaOJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Pipeline: Standardize X -> LinearRegression (multi-output)\n",
        "mvr_pipeline = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),       # scales predictors X_ex\n",
        "    (\"reg\",    LinearRegression())\n",
        "])\n",
        "\n",
        "mvr_pipeline.fit(X_ex, Y_phys)\n",
        "\n",
        "# Predictions\n",
        "Y_hat = pd.DataFrame(mvr_pipeline.predict(X_ex), columns=Y_phys.columns)\n",
        "\n",
        "# Per-response R^2 and RMSE\n",
        "r2_each = r2_score(Y_phys, Y_hat, multioutput=\"raw_values\")\n",
        "mse_each = mean_squared_error(Y_phys, Y_hat, multioutput=\"raw_values\")\n",
        "rmse_each = np.sqrt(mse_each)\n",
        "\n",
        "perf = pd.DataFrame({\n",
        "    \"Response\": Y_phys.columns,\n",
        "    \"R2\": r2_each,\n",
        "    \"RMSE\": rmse_each\n",
        "})\n",
        "\n",
        "print(\"In-sample multivariate regression performance (pipeline):\")\n",
        "display(perf)"
      ],
      "metadata": {
        "id": "NYvZxsdPNeZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Residual diagnostics (normality, homoscedasticity)"
      ],
      "metadata": {
        "id": "j03bNcI_NnjZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "residuals = Y_phys - Y_hat\n",
        "\n",
        "for col in Y_phys.columns:\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
        "\n",
        "    # Residual vs fitted\n",
        "    axes[0].scatter(Y_hat[col], residuals[col])\n",
        "    axes[0].axhline(0, color=\"gray\", linewidth=0.8)\n",
        "    axes[0].set_xlabel(\"Fitted values\")\n",
        "    axes[0].set_ylabel(\"Residuals\")\n",
        "    axes[0].set_title(f\"{col}: Residuals vs Fitted\")\n",
        "\n",
        "    # Q-Q plot\n",
        "    sm.qqplot(residuals[col], line=\"45\", ax=axes[1])\n",
        "    axes[1].set_title(f\"{col}: Q-Q Plot\")\n",
        "\n",
        "    fig.suptitle(f\"Diagnostics for {col}\")\n",
        "    fig.tight_layout()\n",
        "    fig.savefig(os.path.join(FIG_DIR, f\"diagnostics_{col.lower()}.png\"), dpi=300)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "EEsVSkssNrR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MANOVA for multivariate significance"
      ],
      "metadata": {
        "id": "nNRf6qRMNhVw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a single DataFrame for MANOVA\n",
        "df_reg = pd.concat([Y_phys, X_ex], axis=1)\n",
        "formula = \"Weight + Waist + Pulse ~ Chins + Situps + Jumps\"\n",
        "\n",
        "maov = MANOVA.from_formula(formula, data=df_reg)\n",
        "print(maov.mv_test())"
      ],
      "metadata": {
        "id": "rBl5ozb4NkI-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}